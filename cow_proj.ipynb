{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR7NubkBlPqO",
        "outputId": "592fdedc-b2d3-4c9a-a817-769585d3b9a2"
      },
      "outputs": [],
      "source": [
        "#su colab\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#video_path = '/content/drive/MyDrive/mucche/mucchine.mp4'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LhsUJkftmB7L"
      },
      "outputs": [],
      "source": [
        "#su vs code\n",
        "\n",
        "video_path = 'DJI_0429_cut.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "        raise RuntimeError(\"Impossibile aprire il video.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9C6yPFmPoAo1"
      },
      "outputs": [],
      "source": [
        "fps = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsmn8VrHoGvq",
        "outputId": "bc2de40f-daf2-4834-f6d1-482dd9bf6de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames: 282\n",
            "durata video: 9.4 s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(\"frames:\", frame_count)\n",
        "duration = frame_count / fps\n",
        "print(\"durata video:\", duration, \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eopFNefprO2",
        "outputId": "8949b105-e55a-40c4-9301-f906110f4d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (8.3.231)\n",
            "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (3.9.4)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (2.32.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (2.8.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (0.23.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (7.0.0)\n",
            "Requirement already satisfied: polars>=0.20.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (1.35.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.23.0)\n",
            "Requirement already satisfied: polars-runtime-32==1.35.2 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.35.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elisa\\miniconda3\\envs\\mucche\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uLvYerppkEQ",
        "outputId": "76836889-93c0-4895-ce8e-99144afc9550"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg8Hc0nLqnCI"
      },
      "source": [
        "*Classe traker che ho copiato e adattato*:\n",
        "\n",
        "Tracker called for each new frame with a list of detections (from a YOLO model).\n",
        "\n",
        "Matching: It calculates the distances between the centroids of existing tracks and new detections. It then tries to match new detections to existing tracks based on proximity (greedy matching).\n",
        "\n",
        "Updating: If an existing track is successfully matched to a new detection, its centroid and last_frame are updated.\n",
        "\n",
        "New Tracks: Any detections that couldn't be matched to an existing track are considered new objects, and a new track with a unique ID is created for them.\n",
        "\n",
        "Handling Lost Tracks: If a track is not matched in a given frame, its 'lost' counter increases. If this counter exceeds max_lost_frames, the track is removed, assuming the object has left the scene or is no longer detectable.\n",
        "\n",
        "In essence, it takes raw object detections from each frame and tries to maintain a consistent identity for each object over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZjBqPjf9pP_2"
      },
      "outputs": [],
      "source": [
        "class tracker:\n",
        "    def __init__(self, max_lost_frames=5, max_distance=80):\n",
        "        self.next_id = 0\n",
        "        self.tracks = {}  # id -> dict{centroid, last_frame, history(deque of (frame_idx, centroid, speed, accel, grouping))}\n",
        "        self.max_lost = max_lost_frames\n",
        "        self.max_dist = max_distance\n",
        "\n",
        "    def update(self, detections, frame_idx, timestamp):\n",
        "        \"\"\"\n",
        "        detections: list of (cx, cy, bbox, conf)\n",
        "        returns: list of (id, cx, cy, bbox, conf)\n",
        "        \"\"\"\n",
        "        assigned = {}\n",
        "        out = []\n",
        "\n",
        "        # prepare arrays\n",
        "        det_centroids = np.array([[d[0], d[1]] for d in detections]) if detections else np.empty((0, 2))\n",
        "        track_ids = list(self.tracks.keys())\n",
        "        track_centroids = np.array([self.tracks[t]['centroid'] for t in track_ids]) if track_ids else np.empty((0, 2))\n",
        "\n",
        "        if len(track_centroids) and len(det_centroids):\n",
        "            # distance matrix\n",
        "            dmat = np.linalg.norm(track_centroids[:, None, :] - det_centroids[None, :, :], axis=2)\n",
        "            # greedy matching\n",
        "            while True:\n",
        "                i, j = np.unravel_index(np.argmin(dmat), dmat.shape)\n",
        "                if not np.isfinite(dmat[i, j]):\n",
        "                    break\n",
        "                if dmat[i, j] > self.max_dist:\n",
        "                    break\n",
        "                tid = track_ids[i]\n",
        "                assigned[tid] = j\n",
        "                dmat[i, :] = np.inf\n",
        "                dmat[:, j] = np.inf\n",
        "                if np.all(np.isinf(dmat)):\n",
        "                    break\n",
        "\n",
        "        used_dets = set(assigned.values())\n",
        "        # update assigned tracks\n",
        "        for tid, j in assigned.items():\n",
        "            cx, cy, bbox, conf = detections[j]\n",
        "            self.tracks[tid]['centroid'] = (cx, cy)\n",
        "            self.tracks[tid]['last_frame'] = frame_idx\n",
        "            out.append((tid, cx, cy, bbox, conf))\n",
        "\n",
        "        # create new tracks for unassigned detections\n",
        "        for idx, det in enumerate(detections):\n",
        "            if idx in used_dets:\n",
        "                continue\n",
        "            cx, cy, bbox, conf = det\n",
        "            tid = self.next_id\n",
        "            self.next_id += 1\n",
        "            self.tracks[tid] = {\n",
        "                'centroid': (cx, cy),\n",
        "                'last_frame': frame_idx,\n",
        "                'history': deque(maxlen=256),  # keep history for speed/accel windows\n",
        "                'lost': 0\n",
        "            }\n",
        "            out.append((tid, cx, cy, bbox, conf))\n",
        "\n",
        "        # increment lost counters and remove stale tracks\n",
        "        to_delete = []\n",
        "        for tid in list(self.tracks.keys()):\n",
        "            if self.tracks[tid]['last_frame'] != frame_idx:\n",
        "                self.tracks[tid]['lost'] = self.tracks[tid].get('lost', 0) + 1\n",
        "                if self.tracks[tid]['lost'] > self.max_lost:\n",
        "                    to_delete.append(tid)\n",
        "        for tid in to_delete:\n",
        "            del self.tracks[tid]\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "trk = tracker(max_lost_frames=5, max_distance=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Vg0p33qFZ6",
        "outputId": "b23c12bc-ec6a-4ee8-c584-36c02f9e85c9"
      },
      "outputs": [],
      "source": [
        "#per riconoscimento mucche uso yolo (classe 19)\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OP1XslehtB4d"
      },
      "outputs": [],
      "source": [
        "def id_to_color(track_id):\n",
        "    np.random.seed(track_id)\n",
        "    return tuple(int(c) for c in np.random.randint(0, 255, size=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prova detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkRA9I777EzC",
        "outputId": "2bccaa2d-aa10-4906-9c9e-2184755d6f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DJI_0429_cut_debug_id.mp4\n",
            "Video mucche con id salvato.\n"
          ]
        }
      ],
      "source": [
        "#BLOCCO CHE SALVA IL VIDEO CON IL TRAKING DELLE MUCCHE, metti true se lo vuoi salvare\n",
        "debug_id = True\n",
        "output_video = video_path.rsplit('.', 1)[0] + \"_debug_id.mp4\"\n",
        "print(output_video)\n",
        "if debug_id and output_video is not None:\n",
        "    if output_video.endswith('.mp4'):\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(output_video, fourcc, fps, (frame_w, frame_h))\n",
        "    else:\n",
        "        print(\"metti un mp4\")\n",
        "    frame_idx = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        #results = model(frame, conf=0.4, iou=0.5)[0]\n",
        "        results = model.predict(frame, imgsz=max(frame_w, frame_h), conf=0.2, verbose=False)[0]\n",
        "\n",
        "        detections = []\n",
        "        for box in results.boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            if cls != 19:  # cow\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cx = int((x1 + x2) / 2)\n",
        "            cy = int((y1 + y2) / 2)\n",
        "            conf = float(box.conf[0])\n",
        "\n",
        "            detections.append((cx, cy, (x1, y1, x2, y2), conf))\n",
        "\n",
        "        tracks = trk.update(detections, frame_idx, timestamp=None)\n",
        "\n",
        "        for tid, cx, cy, bbox, conf in tracks:\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            color = id_to_color(tid)\n",
        "\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"ID {tid}\",\n",
        "                (x1, y1 - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.6,\n",
        "                color,\n",
        "                2\n",
        "            )\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(\"Video mucche con id salvato.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPGig8AaBAeB"
      },
      "source": [
        "# Prova direzioni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xjtRBnGKxp0K"
      },
      "outputs": [],
      "source": [
        "def estimate_camera_motion_farneback(prev_gray, gray, centroids):\n",
        "    \"\"\"\n",
        "    Stima il movimento della camera usando Farneback optical flow denso,\n",
        "    escludendo le zone intorno ai centroidi delle mucche.\n",
        "    centroids: lista di (cx, cy) da mascherare\n",
        "    \"\"\"\n",
        "    if prev_gray is None or gray is None:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    #crea maschera escludendo cerchi intorno ai centroidi delle mucche\n",
        "\n",
        "    mask = np.ones_like(gray, dtype=np.uint8) * 255\n",
        "    if centroids is not None:\n",
        "        for (cx, cy) in centroids:\n",
        "            x, y = int(cx), int(cy)\n",
        "            cv2.circle(mask, (x, y), 30, 0, -1)\n",
        "\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
        "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    valid_mask = mask > 0\n",
        "    if not np.any(valid_mask):\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    dx = float(np.median(flow[:, :, 0][valid_mask]))\n",
        "    dy = float(np.median(flow[:, :, 1][valid_mask]))\n",
        "\n",
        "    return dx, dy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jCQGtWDVvuz6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DJI_0429_cut_debug_frecce.mp4\n",
            "Video mucche con id salvato.\n"
          ]
        }
      ],
      "source": [
        "debug_frecce = True\n",
        "output_video = video_path.rsplit('.', 1)[0] + \"_debug_frecce.mp4\"\n",
        "print(output_video)\n",
        "if debug_frecce and output_video is not None:\n",
        "    if output_video.endswith('.mp4'):\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(output_video, fourcc, fps, (frame_w, frame_h))\n",
        "    else:\n",
        "        print(\"metti un mp4\")\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "            raise RuntimeError(\"Impossibile aprire il video.\")\n",
        "        \n",
        "\n",
        "    frame_idx = 0\n",
        "    cam_dx, cam_dy = 0.0, 0.0\n",
        "    prev_gray = None\n",
        "    camera_motion_history = deque(maxlen=10)  # storia ultimi 10 frame per smoothing\n",
        "    COW_MOTION_THRESHOLD = 4  # px/frame (regolabile)\n",
        "\n",
        "    # Dizionario per tracciare posizioni precedenti delle mucche\n",
        "    prev_cow_positions = {}\n",
        "    cow_disturbance_index = {}  # indice di disturbo per ogni mucca\n",
        "    cow_movement_history = {}  # storia movimenti per ogni mucca per smoothing\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        #results = model(frame, conf=0.4, iou=0.5)[0]\n",
        "        results = model.predict(frame, imgsz=max(frame_w, frame_h), conf=0.2, verbose=False)[0]\n",
        "        detections = []\n",
        "        for box in results.boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            if cls != 19:  # cow\n",
        "                continue\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cx = int((x1 + x2) / 2)\n",
        "            cy = int((y1 + y2) / 2)\n",
        "            conf = float(box.conf[0])\n",
        "            detections.append((cx, cy, (x1, y1, x2, y2), conf))\n",
        "        tracks = trk.update(detections, frame_idx, timestamp=None)\n",
        "        #bboxes = [bbox for tid, cx, cy, bbox, conf in tracks]\n",
        "        centroids = {tid: (cx, cy) for (tid, cx, cy, _, _) in tracks}\n",
        "        centroid_list = list(centroids.values())\n",
        "\n",
        "        if prev_gray is not None:\n",
        "            cam_dx_raw, cam_dy_raw = estimate_camera_motion_farneback(prev_gray, gray, centroid_list)\n",
        "            camera_motion_history.append((cam_dx_raw, cam_dy_raw))\n",
        "            #media sugli ultimi N frame per smoothing (per non far vibrare troppo le frecce)\n",
        "            if len(camera_motion_history) > 0:\n",
        "                cam_dx = float(np.mean([m[0] for m in camera_motion_history]))\n",
        "                cam_dy = float(np.mean([m[1] for m in camera_motion_history]))\n",
        "            else:\n",
        "                cam_dx, cam_dy = cam_dx_raw, cam_dy_raw\n",
        "        else:\n",
        "            cam_dx, cam_dy = 0.0, 0.0\n",
        "            \n",
        "        \n",
        "        #calcola movimento mucca\n",
        "        cow_movements = {}\n",
        "        for tid, cx, cy, bbox, conf in tracks:\n",
        "            if tid in prev_cow_positions:\n",
        "                prev_cx, prev_cy = prev_cow_positions[tid]\n",
        "                # Movimento assoluto della mucca\n",
        "                abs_dx = cx - prev_cx\n",
        "                abs_dy = cy - prev_cy\n",
        "                # Movimento relativo (compensando il movimento della camera)\n",
        "                rel_dx = abs_dx - cam_dx\n",
        "                rel_dy = abs_dy - cam_dy\n",
        "                # Magnitudine del movimento\n",
        "                movement_magnitude = np.sqrt(rel_dx**2 + rel_dy**2)\n",
        "                \n",
        "                # Aggiorna storia movimenti per smoothing\n",
        "                if tid not in cow_movement_history:\n",
        "                    cow_movement_history[tid] = deque(maxlen=5)  # ultimi 5 frame per smoothing\n",
        "                cow_movement_history[tid].append((rel_dx, rel_dy, movement_magnitude))\n",
        "                \n",
        "                # Calcola movimento smoothed\n",
        "                if len(cow_movement_history[tid]) > 0:\n",
        "                    smooth_dx = float(np.mean([m[0] for m in cow_movement_history[tid]]))\n",
        "                    smooth_dy = float(np.mean([m[1] for m in cow_movement_history[tid]]))\n",
        "                    smooth_magnitude = float(np.mean([m[2] for m in cow_movement_history[tid]]))\n",
        "                else:\n",
        "                    smooth_dx, smooth_dy, smooth_magnitude = rel_dx, rel_dy, movement_magnitude\n",
        "                \n",
        "                cow_movements[tid] = (smooth_dx, smooth_dy, smooth_magnitude)\n",
        "                \n",
        "                # Aggiorna indice di disturbo (media mobile del movimento)\n",
        "                if tid not in cow_disturbance_index:\n",
        "                    cow_disturbance_index[tid] = deque(maxlen=30)  # ultimi 30 frame\n",
        "                cow_disturbance_index[tid].append(movement_magnitude)\n",
        "            else:\n",
        "                cow_movements[tid] = (0.0, 0.0, 0.0)\n",
        "            \n",
        "            # Aggiorna posizione precedente\n",
        "            prev_cow_positions[tid] = (cx, cy)\n",
        "\n",
        "\n",
        "        if debug_frecce:\n",
        "            #disegna freccia camera in alto a destra (invertita per mostrare direzione movimento camera)\n",
        "            cam_arrow_start = (frame_w - 50, 50)\n",
        "            cam_arrow_end = (int(frame_w - 50 - cam_dx * 10), int(50 - cam_dy * 10))  # scala x10, invertita\n",
        "            cv2.arrowedLine(frame, cam_arrow_start, cam_arrow_end, (0, 255, 255), 3, tipLength=0.3)\n",
        "            cv2.putText(frame, \"Camera\", (frame_w - 120, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "            \n",
        "            #disegna frecce mucche solo se si muovono più di una soglia COW_MOTION_THRESHOLD\n",
        "            for tid, cx, cy, bbox, conf in tracks:\n",
        "                color = id_to_color(tid)\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                \n",
        "                # Disegna bounding box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                \n",
        "                if tid in cow_movements:\n",
        "                    rel_dx, rel_dy, movement_magnitude = cow_movements[tid]\n",
        "                    \n",
        "                    # Disegna freccia solo se il movimento supera la soglia\n",
        "                    if movement_magnitude > COW_MOTION_THRESHOLD:\n",
        "                        arrow_start = (cx, cy)\n",
        "                        arrow_end = (int(cx + rel_dx * 5), int(cy + rel_dy * 5))  # scala x5 per visibilità\n",
        "                        cv2.arrowedLine(frame, arrow_start, arrow_end, color, 2, tipLength=0.3)\n",
        "            \n",
        "            #scrivi indice di disturbo per ogni mucca\n",
        "            for tid, cx, cy, bbox, conf in tracks:\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                color = id_to_color(tid)\n",
        "                \n",
        "                # Calcola indice di disturbo medio\n",
        "                if tid in cow_disturbance_index and len(cow_disturbance_index[tid]) > 0:\n",
        "                    avg_disturbance = np.mean(cow_disturbance_index[tid])\n",
        "                    disturbance_text = f\"ID {tid} - CDI: {avg_disturbance:.2f}\"\n",
        "                else:\n",
        "                    disturbance_text = f\"ID {tid} - CDI: 0.00\"\n",
        "                \n",
        "                cv2.putText(frame, disturbance_text, (x1, y1 - 5), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "        prev_gray = gray.copy()\n",
        "        \n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(\"Video mucche con id salvato.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prova indice di disturbo basato su direzioni e velocità"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DJI_0429_cut_cdi_visual.mp4\n",
            "Video con indice di disturbo visivo salvato.\n"
          ]
        }
      ],
      "source": [
        "output_video = video_path.rsplit('.', 1)[0] + \"_cdi_visual.mp4\"\n",
        "print(output_video)\n",
        "if output_video.endswith('.mp4'):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    writer = cv2.VideoWriter(output_video, fourcc, fps, (frame_w, frame_h))\n",
        "else:\n",
        "    print(\"metti un mp4\")\n",
        "debug_frecce = False\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Impossibile aprire il video.\")\n",
        "    \n",
        "\n",
        "frame_idx = 0\n",
        "cam_dx, cam_dy = 0.0, 0.0\n",
        "prev_gray = None\n",
        "camera_motion_history = deque(maxlen=10)  # storia ultimi 10 frame per smoothing\n",
        "COW_MOTION_THRESHOLD = 4  # px/frame (regolabile)\n",
        "CDI_MAX = 10.0  # valore massimo per normalizzare l'indice di disturbo (regolabile)\n",
        "\n",
        "# Dizionario per tracciare posizioni precedenti delle mucche\n",
        "prev_cow_positions = {}\n",
        "cow_disturbance_index = {}  # indice di disturbo per ogni mucca\n",
        "cow_movement_history = {}  # storia movimenti per ogni mucca per smoothing\n",
        "\n",
        "def get_cdi_color(cdi_value, max_cdi=10.0):\n",
        "    \"\"\"\n",
        "    Restituisce un colore BGR in base al CDI (verde -> giallo -> rosso)\n",
        "    cdi_value: valore CDI da 0 a max_cdi\n",
        "    \"\"\"\n",
        "    # Normalizza tra 0 e 1\n",
        "    normalized = min(cdi_value / max_cdi, 1.0)\n",
        "    \n",
        "    if normalized < 0.5:\n",
        "        # Verde -> Giallo (0-0.5)\n",
        "        # B rimane 0, G rimane 255, R aumenta\n",
        "        r = int(normalized * 2 * 255)\n",
        "        g = 255\n",
        "        b = 0\n",
        "    else:\n",
        "        # Giallo -> Rosso (0.5-1.0)\n",
        "        # B rimane 0, R rimane 255, G diminuisce\n",
        "        r = 255\n",
        "        g = int((1.0 - normalized) * 2 * 255)\n",
        "        b = 0\n",
        "    \n",
        "    return (b, g, r)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    results = model.predict(frame, imgsz=max(frame_w, frame_h), conf=0.2, verbose=False)[0]\n",
        "    detections = []\n",
        "    for box in results.boxes:\n",
        "        cls = int(box.cls[0])\n",
        "        if cls != 19:  # cow\n",
        "            continue\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "        conf = float(box.conf[0])\n",
        "        detections.append((cx, cy, (x1, y1, x2, y2), conf))\n",
        "    tracks = trk.update(detections, frame_idx, timestamp=None)\n",
        "    centroids = {tid: (cx, cy) for (tid, cx, cy, _, _) in tracks}\n",
        "    centroid_list = list(centroids.values())\n",
        "\n",
        "    if prev_gray is not None:\n",
        "        cam_dx_raw, cam_dy_raw = estimate_camera_motion_farneback(prev_gray, gray, centroid_list)\n",
        "        camera_motion_history.append((cam_dx_raw, cam_dy_raw))\n",
        "        if len(camera_motion_history) > 0:\n",
        "            cam_dx = float(np.mean([m[0] for m in camera_motion_history]))\n",
        "            cam_dy = float(np.mean([m[1] for m in camera_motion_history]))\n",
        "        else:\n",
        "            cam_dx, cam_dy = cam_dx_raw, cam_dy_raw\n",
        "    else:\n",
        "        cam_dx, cam_dy = 0.0, 0.0\n",
        "        \n",
        "    \n",
        "    # Calcola movimento mucca\n",
        "    cow_movements = {}\n",
        "    for tid, cx, cy, bbox, conf in tracks:\n",
        "        if tid in prev_cow_positions:\n",
        "            prev_cx, prev_cy = prev_cow_positions[tid]\n",
        "            abs_dx = cx - prev_cx\n",
        "            abs_dy = cy - prev_cy\n",
        "            rel_dx = abs_dx - cam_dx\n",
        "            rel_dy = abs_dy - cam_dy\n",
        "            movement_magnitude = np.sqrt(rel_dx**2 + rel_dy**2)\n",
        "            \n",
        "            if tid not in cow_movement_history:\n",
        "                cow_movement_history[tid] = deque(maxlen=5)\n",
        "            cow_movement_history[tid].append((rel_dx, rel_dy, movement_magnitude))\n",
        "            \n",
        "            if len(cow_movement_history[tid]) > 0:\n",
        "                smooth_dx = float(np.mean([m[0] for m in cow_movement_history[tid]]))\n",
        "                smooth_dy = float(np.mean([m[1] for m in cow_movement_history[tid]]))\n",
        "                smooth_magnitude = float(np.mean([m[2] for m in cow_movement_history[tid]]))\n",
        "            else:\n",
        "                smooth_dx, smooth_dy, smooth_magnitude = rel_dx, rel_dy, movement_magnitude\n",
        "            \n",
        "            cow_movements[tid] = (smooth_dx, smooth_dy, smooth_magnitude)\n",
        "            \n",
        "            if tid not in cow_disturbance_index:\n",
        "                cow_disturbance_index[tid] = deque(maxlen=30)\n",
        "            cow_disturbance_index[tid].append(movement_magnitude)\n",
        "        else:\n",
        "            cow_movements[tid] = (0.0, 0.0, 0.0)\n",
        "        \n",
        "        prev_cow_positions[tid] = (cx, cy)\n",
        "\n",
        "    # Disegna indicatori CDI\n",
        "    cam_arrow_start = (frame_w - 50, 50)\n",
        "    cam_arrow_end = (int(frame_w - 50 - cam_dx * 10), int(50 - cam_dy * 10))\n",
        "    cv2.arrowedLine(frame, cam_arrow_start, cam_arrow_end, (0, 255, 255), 2, tipLength=0.3)\n",
        "    cv2.putText(frame, \"Cam\", (frame_w - 90, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
        "    \n",
        "    for tid, cx, cy, bbox, conf in tracks:\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        \n",
        "        # Calcola CDI medio\n",
        "        if tid in cow_disturbance_index and len(cow_disturbance_index[tid]) > 0:\n",
        "            avg_disturbance = np.mean(cow_disturbance_index[tid])\n",
        "        else:\n",
        "            avg_disturbance = 0.0\n",
        "        \n",
        "        # Ottieni colore in base al CDI\n",
        "        color = get_cdi_color(avg_disturbance, CDI_MAX)\n",
        "        \n",
        "        # Disegna bounding box con colore CDI\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
        "        \n",
        "        # Disegna barra CDI sopra la mucca\n",
        "        bar_width = x2 - x1\n",
        "        bar_height = 10\n",
        "        bar_x1 = x1\n",
        "        bar_y1 = y1 - 25\n",
        "        bar_x2 = x2\n",
        "        bar_y2 = y1 - 15\n",
        "        \n",
        "        # Sfondo barra (grigio)\n",
        "        cv2.rectangle(frame, (bar_x1, bar_y1), (bar_x2, bar_y2), (80, 80, 80), -1)\n",
        "        \n",
        "        # Riempimento barra in base al CDI\n",
        "        fill_width = int(bar_width * min(avg_disturbance / CDI_MAX, 1.0))\n",
        "        if fill_width > 0:\n",
        "            cv2.rectangle(frame, (bar_x1, bar_y1), (bar_x1 + fill_width, bar_y2), color, -1)\n",
        "        \n",
        "        # Bordo barra\n",
        "        cv2.rectangle(frame, (bar_x1, bar_y1), (bar_x2, bar_y2), (255, 255, 255), 1)\n",
        "        \n",
        "        # Testo CDI\n",
        "        disturbance_text = f\"ID{tid}: {avg_disturbance:.1f}\"\n",
        "        cv2.putText(frame, disturbance_text, (x1, y1 - 30), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, disturbance_text, (x1, y1 - 30), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "        \n",
        "        # Disegna freccia movimento se supera soglia (opzionale)\n",
        "        if debug_frecce and tid in cow_movements:\n",
        "            rel_dx, rel_dy, movement_magnitude = cow_movements[tid]\n",
        "            if movement_magnitude > COW_MOTION_THRESHOLD:\n",
        "                arrow_start = (cx, cy)\n",
        "                arrow_end = (int(cx + rel_dx * 5), int(cy + rel_dy * 5))\n",
        "                cv2.arrowedLine(frame, arrow_start, arrow_end, color, 2, tipLength=0.3)\n",
        "\n",
        "    writer.write(frame)\n",
        "    frame_idx += 1\n",
        "    prev_gray = gray.copy()\n",
        "    \n",
        "cap.release()\n",
        "writer.release()\n",
        "print(\"Video con indice di disturbo visivo salvato.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do:\n",
        "\n",
        "- ~~prova occhi~~\n",
        "- indice medio\n",
        "- grafico disturbo nel tempo\n",
        "- prova su video esteso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mucche",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
